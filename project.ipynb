{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 7 Project\n",
        "\n",
        "This week's project will investigate issues in a quadcopter controller based using a linear quadratic regulator.\n",
        "You will start with an existing model of the system and logs from a quadcopter based on it, investigate discrepancies, and ultimately train a new model of the system dynamics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTIhFidP-KvD"
      },
      "source": [
        "The full project description and a template notebook are available on GitHub: [Project 7 Materials](https://github.com/bu-cds-dx704/dx704-project-07).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52eGFDLZdsBy"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7IKpQFK_AGF"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "You've just joined a drone startup.\n",
        "On your first day, you join your new team to watch a test flight for a new quadcopter prototype.\n",
        "Watching the prototype fly, the team comments that it is not as smooth as usual and suspects that something is off in the controller.\n",
        "They provide you a copy of the dynamics model and log data from the prototype to investigate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ks7EK6h3ktC"
      },
      "source": [
        "The quadcopter control model is a slightly more sophisticated version of the 1D quadcopter problem previously considered.\n",
        "\n",
        "The state vector $\\mathbf{x}_t$ now includes an acceleration component, and the action vector now has a servo control for the throttle instead of a raw force component.\n",
        "\\begin{array}{rcl}\n",
        "\\mathbf{x}_t & = & \\begin{bmatrix} x_t \\\\ v_t \\\\ a_t \\end{bmatrix} \\\\\n",
        "\\mathbf{u_t} & = & \\begin{bmatrix} u_t \\end{bmatrix}\n",
        "\\end{array}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oSLkMqvMFF"
      },
      "source": [
        "## Part 1: Reconstruct the Control Matrix\n",
        "\n",
        "You are provided the dynamics model in the files `model-A.tsv`, `model-B.tsv`, `cost-Q.tsv` and `cost-R.tsv`.\n",
        "Recompute the control matrix $\\mathbf{K}$ to be used in the infinite horizon linear quadratic regulator problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, json, math, re, gc\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Paths (all files are already uploaded next to the notebook)\n",
        "DATA_DIR = Path(\".\")\n",
        "PATH_TRAIN = DATA_DIR / \"qc-train.tsv\"\n",
        "PATH_LOG   = DATA_DIR / \"qc-log.tsv\"\n",
        "PATH_A     = DATA_DIR / \"model-A.tsv\"\n",
        "PATH_B     = DATA_DIR / \"model-B.tsv\"\n",
        "PATH_CQ    = DATA_DIR / \"cost-Q.tsv\"\n",
        "PATH_CR    = DATA_DIR / \"cost-R.tsv\"\n",
        "\n",
        "# Verify presence\n",
        "for p in [PATH_TRAIN, PATH_LOG, PATH_A, PATH_B, PATH_CQ, PATH_CR]:\n",
        "    assert p.exists(), f\"Missing file: {p}\"\n",
        "\n",
        "# Global output folder\n",
        "OUT_DIR = Path(\"qc_outputs\")\n",
        "OUT_DIR.mkdir(exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Pdpurx_Ym3F6"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def _read_matrix_tsv(path):\n",
        "    df = pd.read_csv(path, sep=\"\\t\")\n",
        "    num = df.select_dtypes(include=[\"number\"])\n",
        "    if num.shape[1] == 0 and df.shape[1] > 1:\n",
        "        num = df.iloc[:, 1:].select_dtypes(include=[\"number\"])\n",
        "    num = num.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)\n",
        "    return num.to_numpy(dtype=float)\n",
        "\n",
        "# Use in-memory A,B,Q,R if present; else read via your setup paths\n",
        "if 'A' not in globals(): A = _read_matrix_tsv(PATH_A)\n",
        "if 'B' not in globals(): B = _read_matrix_tsv(PATH_B)\n",
        "if 'Q' not in globals():\n",
        "    # your setup uses PATH_CQ\n",
        "    Q = _read_matrix_tsv(PATH_CQ)\n",
        "if 'R' not in globals():\n",
        "    # your setup uses PATH_CR\n",
        "    R = _read_matrix_tsv(PATH_CR)\n",
        "\n",
        "# Shape checks\n",
        "n = A.shape[0]\n",
        "m = B.shape[1]\n",
        "assert A.shape == (n, n), \"A must be square (n×n).\"\n",
        "assert B.shape[0] == n,   \"B must have n rows.\"\n",
        "assert Q.shape == (n, n), \"Q must be n×n.\"\n",
        "assert R.shape == (m, m), \"R must be m×m.\"\n",
        "\n",
        "# DARE (iterative) and LQR gain\n",
        "def _dare_iter(A, B, Q, R, tol=1e-12, max_iter=10000, ridge=1e-12):\n",
        "    P = Q.copy()\n",
        "    Rm = R.copy()\n",
        "    try:\n",
        "        np.linalg.cholesky(Rm)\n",
        "    except np.linalg.LinAlgError:\n",
        "        Rm = Rm + ridge * np.eye(Rm.shape[0])\n",
        "    for _ in range(max_iter):\n",
        "        BtP = B.T @ P\n",
        "        G = Rm + BtP @ B\n",
        "        Ktmp = np.linalg.solve(G, BtP @ A)           # (R + Bᵀ P B)^{-1} Bᵀ P A\n",
        "        Pn = A.T @ P @ (A - B @ Ktmp) + Q\n",
        "        if np.linalg.norm(Pn - P, 'fro') <= tol * max(1.0, np.linalg.norm(P, 'fro')):\n",
        "            P = Pn\n",
        "            break\n",
        "        P = Pn\n",
        "    return P\n",
        "\n",
        "def _dlqr(A, B, Q, R):\n",
        "    P = _dare_iter(A, B, Q, R)\n",
        "    BtP = B.T @ P\n",
        "    K = np.linalg.solve(R + BtP @ B, BtP @ A)        # u = -K x\n",
        "    return K, P\n",
        "\n",
        "K_intended, _ = _dlqr(A, B, Q, R)   # keep as K_intended for the save cell\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDS1s6W9m5G1"
      },
      "source": [
        "Save $\\mathbf{K}$ in a file \"control-K-intended.tsv\" with columns x, v and a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "heCP8JhgnEIC"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "assert 'K_intended' in globals(), \"Run the compute cell first to define K_intended.\"\n",
        "K_to_save = np.asarray(K_intended, dtype=float)\n",
        "\n",
        "# Spec: columns x, v, a → expect a single-input, 3-state system (K is 1×3)\n",
        "assert K_to_save.shape == (1, 3), f\"Expected K to be 1×3 (x, v, a). Got {K_to_save.shape}.\"\n",
        "\n",
        "pd.DataFrame([K_to_save.ravel()], columns=[\"x\", \"v\", \"a\"]).to_csv(\n",
        "    \"control-K-intended.tsv\", sep=\"\\t\", index=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emwSwtKjnG8y"
      },
      "source": [
        "Submit \"control-K-intended.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqbtALHx_z7l"
      },
      "source": [
        "## Part 2: Recompute the Actions for the Logged States\n",
        "\n",
        "You get access to the log data for the prototype as the file \"qc-log.tsv\".\n",
        "It conveniently saves all the state and actions made.\n",
        "Recompute the actions based on your $\\mathbf{K}$ matrix computed in part 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DsbCg2TjoFpp"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# 1) Load log\n",
        "log_df = pd.read_csv(PATH_LOG, sep=\"\\t\")\n",
        "\n",
        "# 2) Get K (prefer in-memory from Part 1; else load from file)\n",
        "if 'K_intended' in globals():\n",
        "    K = np.asarray(K_intended, dtype=float)\n",
        "else:\n",
        "    K_file = Path(\"control-K-intended.tsv\")\n",
        "    assert K_file.exists(), \"control-K-intended.tsv not found and K_intended not in memory. Run Part 1 (save cell) first.\"\n",
        "    K = pd.read_csv(K_file, sep=\"\\t\").to_numpy(dtype=float).reshape(1, -1)\n",
        "\n",
        "# Expect a 1×3 gain (x, v, a)\n",
        "assert K.shape == (1, 3), f\"Expected K to be 1×3 (x, v, a). Got {K.shape}\"\n",
        "\n",
        "# 3) Find state columns in the log (prefer exact x,v,a; fall back to best guess of 3 numeric cols)\n",
        "def _find_state_columns(df: pd.DataFrame):\n",
        "    cols_lower = {c.lower(): c for c in df.columns}\n",
        "    if all(k in cols_lower for k in (\"x\",\"v\",\"a\")):\n",
        "        return [cols_lower[\"x\"], cols_lower[\"v\"], cols_lower[\"a\"]]\n",
        "    # try common synonyms\n",
        "    candidates = {}\n",
        "    for want, keys in {\n",
        "        \"x\": [\"x\",\"pos\",\"position\"],\n",
        "        \"v\": [\"v\",\"vel\",\"velocity\"],\n",
        "        \"a\": [\"a\",\"acc\",\"accel\",\"acceleration\"],\n",
        "    }.items():\n",
        "        for k in keys:\n",
        "            for c in df.columns:\n",
        "                if k == c.lower():\n",
        "                    candidates[want] = c\n",
        "                    break\n",
        "            if want in candidates:\n",
        "                break\n",
        "    if len(candidates) == 3:\n",
        "        return [candidates[\"x\"], candidates[\"v\"], candidates[\"a\"]]\n",
        "    # fallback: first three numeric columns\n",
        "    num_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "    assert len(num_cols) >= 3, \"Could not find state columns x,v,a and fewer than 3 numeric columns available in qc-log.tsv.\"\n",
        "    return num_cols[:3]\n",
        "\n",
        "state_cols = _find_state_columns(log_df)\n",
        "\n",
        "# 4) Build state matrix X (n×3) and compute u = -K x\n",
        "X = log_df[state_cols].to_numpy(dtype=float)            # shape (n,3)\n",
        "u_check = -(X @ K.T).reshape(-1)                        # shape (n,)\n",
        "\n",
        "# 5) Choose index column: use existing 'index' if present, else DataFrame index\n",
        "index_col = \"index\" if \"index\" in log_df.columns else None\n",
        "idx_values = log_df[index_col].to_numpy() if index_col else log_df.index.to_numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z2gHEGBoIjL"
      },
      "source": [
        "Save your computed actions as \"qc-check.tsv\" with columns \"index\" and \"u_check\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vbyMYtMLoS72"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "out_df = pd.DataFrame({\"index\": idx_values, \"u_check\": u_check})\n",
        "out_df.to_csv(\"qc-check.tsv\", sep=\"\\t\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDCUyNOfoUzm"
      },
      "source": [
        "Submit \"qc-check.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z20uZNHABA-"
      },
      "source": [
        "## Part 3: Reverse Engineer the Actual Control Matrix\n",
        "\n",
        "Now that you have found a systematic difference between your computed actions and the logged actions, estimate $\n",
        "$, the control matrix that was actually used to choose actions in the prototype."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGoHdtel2iVm"
      },
      "source": [
        "Hint: With a linear quadratic regulator, the optimal actions are always linear combinations of the state that are calculated using the control matrix.\n",
        "You can use linear regression to reverse-engineer the coefficients in the control matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ab7XnMej21RN"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.34043755, 1.30012023, 1.95011696]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Load log\n",
        "log_df = pd.read_csv(PATH_LOG, sep=\"\\t\")\n",
        "\n",
        "# 2) Find state columns (prefer exact x,v,a; otherwise try synonyms; else first 3 numeric)\n",
        "def _find_state_cols(df: pd.DataFrame):\n",
        "    lower = {c.lower(): c for c in df.columns}\n",
        "    if all(k in lower for k in (\"x\",\"v\",\"a\")):\n",
        "        return [lower[\"x\"], lower[\"v\"], lower[\"a\"]]\n",
        "    # common synonyms\n",
        "    candidates = {}\n",
        "    for want, keys in {\n",
        "        \"x\": [\"x\",\"pos\",\"position\"],\n",
        "        \"v\": [\"v\",\"vel\",\"velocity\"],\n",
        "        \"a\": [\"a\",\"acc\",\"accel\",\"acceleration\"],\n",
        "    }.items():\n",
        "        for key in keys:\n",
        "            for c in df.columns:\n",
        "                if c.lower() == key:\n",
        "                    candidates[want] = c\n",
        "                    break\n",
        "            if want in candidates: break\n",
        "    if len(candidates) == 3:\n",
        "        return [candidates[\"x\"], candidates[\"v\"], candidates[\"a\"]]\n",
        "    # fallback: first three numeric columns\n",
        "    nums = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "    assert len(nums) >= 3, \"Could not identify three state columns in qc-log.tsv.\"\n",
        "    return nums[:3]\n",
        "\n",
        "state_cols = _find_state_cols(log_df)\n",
        "\n",
        "# 3) Find the logged action column (prefer 'u'/'action'/'control'; NOT the 'a' state)\n",
        "def _find_action_col(df: pd.DataFrame, state_cols):\n",
        "    preferred = [\"u\",\"action\",\"control\",\"u_cmd\",\"u_applied\",\"act\"]\n",
        "    lower_map = {c.lower(): c for c in df.columns}\n",
        "    for key in preferred:\n",
        "        if key in lower_map and lower_map[key] not in state_cols:\n",
        "            return lower_map[key]\n",
        "    # heuristic: if a column literally named 'u' (case-insensitive) exists, use it\n",
        "    for c in df.columns:\n",
        "        if c.lower() == \"u\" and c not in state_cols:\n",
        "            return c\n",
        "    # fallback: choose a numeric column that is NOT one of the states and varies\n",
        "    num_candidates = [c for c in df.select_dtypes(include=[\"number\"]).columns if c not in state_cols]\n",
        "    assert len(num_candidates) >= 1, \"Could not find an action column in qc-log.tsv.\"\n",
        "    return num_candidates[0]\n",
        "\n",
        "u_col = _find_action_col(log_df, state_cols)\n",
        "\n",
        "# 4) Build design matrix X and target y = -u (no intercept; controller is through the origin)\n",
        "X = log_df[state_cols].to_numpy(dtype=float)      # shape (n,3)\n",
        "u = log_df[u_col].to_numpy(dtype=float).reshape(-1, 1)  # (n,1)\n",
        "y = -u                                            # target is -u\n",
        "\n",
        "# 5) Solve least squares: X k ≈ y  -> k = argmin ||Xk - y||, then K_actual = k^T (1×3)\n",
        "# Use lstsq for numerical robustness (works even if X^T X is near-singular)\n",
        "k_col, *_ = np.linalg.lstsq(X, y, rcond=None)     # k_col shape (3,1)\n",
        "K_actual = k_col.T                                # shape (1,3)\n",
        "\n",
        "# Keep for the save cell\n",
        "K_actual\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7zG_6NT23fq"
      },
      "source": [
        "Save $\\mathbf{K}_{\\mathrm{actual}}$ in \"control-K-actual.tsv\" with the same format as \"control-K-intended.tsv\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hPAaZI3M3DKB"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "assert 'K_actual' in globals(), \"Run the Part 3 compute cell first to define K_actual.\"\n",
        "K_to_save = np.asarray(K_actual, dtype=float)\n",
        "assert K_to_save.shape == (1, 3), f\"Expected K_actual to be 1×3 (x, v, a). Got {K_to_save.shape}.\"\n",
        "\n",
        "pd.DataFrame([K_to_save.ravel()], columns=[\"x\", \"v\", \"a\"]).to_csv(\n",
        "    \"control-K-actual.tsv\", sep=\"\\t\", index=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFmODg3W3D2u"
      },
      "source": [
        "Submit \"control-k-actual.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSuXyz6LAYjK"
      },
      "source": [
        "## Part 4: Recompute the System Dynamics from the Log Data\n",
        "\n",
        "On further investigation, it turns out that the control matrix $\\mathbf{K}$ in the prototype was modified to compensate for state prediction errors.\n",
        "You would like to recompute the $\\mathbf{A}$ and $\\mathbf{B}$ matrices using the log data since they are used to predict the next states.\n",
        "However, since the action vector $\\mathbf{u}_t$ is linearly dependent on the state via $\\mathbf{u}_t=-\\mathbf{K} \\mathbf{x}_t$, you need a new data set so you can separate the effects of the $\\mathbf{A}$ and $\\mathbf{B}$ matrices.\n",
        "Your co-workers kindly provide a new file \"qc-train.tsv\" where noise was added to each action.\n",
        "Estimate the true $\\mathbf{A}$ and $\\mathbf{B}$ matrices based on this file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "13UYre915olG"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load training data\n",
        "train_df = pd.read_csv(PATH_TRAIN, sep=\"\\t\")\n",
        "\n",
        "# Helpers to find state, action, next-state columns\n",
        "def _find_state_cols(df: pd.DataFrame):\n",
        "    lower = {c.lower(): c for c in df.columns}\n",
        "    # prefer exact x, v, a\n",
        "    if all(k in lower for k in (\"x\",\"v\",\"a\")):\n",
        "        return [lower[\"x\"], lower[\"v\"], lower[\"a\"]]\n",
        "    # common synonyms\n",
        "    cand = {}\n",
        "    for want, keys in {\n",
        "        \"x\": [\"x\",\"pos\",\"position\"],\n",
        "        \"v\": [\"v\",\"vel\",\"velocity\"],\n",
        "        \"a\": [\"a\",\"acc\",\"accel\",\"acceleration\"],\n",
        "    }.items():\n",
        "        for key in keys:\n",
        "            for c in df.columns:\n",
        "                if c.lower() == key:\n",
        "                    cand[want] = c\n",
        "                    break\n",
        "            if want in cand: break\n",
        "    if len(cand) == 3:\n",
        "        return [cand[\"x\"], cand[\"v\"], cand[\"a\"]]\n",
        "    # fallback: first three numeric columns\n",
        "    nums = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "    assert len(nums) >= 3, \"Could not identify three state columns in qc-train.tsv.\"\n",
        "    return nums[:3]\n",
        "\n",
        "def _find_action_cols(df: pd.DataFrame, state_cols):\n",
        "    # prefer a single control column 'u' / 'action' / 'control'; keep order if multiple inputs exist\n",
        "    pref = [\"u\",\"u_cmd\",\"u_applied\",\"action\",\"control\",\"act\"]\n",
        "    lower = {c.lower(): c for c in df.columns}\n",
        "    chosen = [lower[k] for k in pref if k in lower and lower[k] not in state_cols]\n",
        "    # add any other numeric non-state columns as potential action components (if multiple inputs)\n",
        "    others = [c for c in df.select_dtypes(include=[\"number\"]).columns if c not in state_cols and c not in chosen]\n",
        "    # Avoid picking obvious index/time columns\n",
        "    others = [c for c in others if not any(tok in c.lower() for tok in [\"time\",\"date\",\"ts\",\"index\",\"id\"])]\n",
        "    if chosen:\n",
        "        return chosen\n",
        "    assert others, \"Could not find an action/control column in qc-train.tsv.\"\n",
        "    return others\n",
        "\n",
        "def _find_next_state_cols(df: pd.DataFrame, state_cols):\n",
        "    # try suffix patterns like x_next, next_x, x1\n",
        "    lower = {c.lower(): c for c in df.columns}\n",
        "    mapping = {}\n",
        "    patterns = [\n",
        "        (\"{s}_next\", lambda s: f\"{s}_next\"),\n",
        "        (\"next_{s}\", lambda s: f\"next_{s}\"),\n",
        "        (\"{s}1\",     lambda s: f\"{s}1\"),\n",
        "        (\"{s}_t1\",   lambda s: f\"{s}_t1\"),\n",
        "        (\"{s}_t+1\",  lambda s: f\"{s}_t+1\"),\n",
        "    ]\n",
        "    base_keys = [c.lower() for c in state_cols]\n",
        "    for base, orig in zip(base_keys, state_cols):\n",
        "        found = None\n",
        "        for _, fmt in patterns:\n",
        "            cand = fmt(base)\n",
        "            if cand in lower:\n",
        "                found = lower[cand]; break\n",
        "        if found:\n",
        "            mapping[orig] = found\n",
        "    if len(mapping) == len(state_cols):\n",
        "        # all found\n",
        "        return [mapping[c] for c in state_cols]\n",
        "    return None  # signal to use shift\n",
        "\n",
        "# Identify columns\n",
        "state_cols = _find_state_cols(train_df)\n",
        "action_cols = _find_action_cols(train_df, state_cols)\n",
        "next_state_cols = _find_next_state_cols(train_df, state_cols)\n",
        "\n",
        "# Order rows by time if a time column exists (for shift fallback)\n",
        "def _guess_time_col(df):\n",
        "    for c in df.columns:\n",
        "        if any(tok in c.lower() for tok in [\"time\",\"timestamp\",\"date\"]):\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "time_col = _guess_time_col(train_df)\n",
        "if time_col is not None:\n",
        "    train_df = train_df.sort_values(time_col)\n",
        "\n",
        "# Build (X_t, U_t, X_{t+1})\n",
        "X_t = train_df[state_cols].to_numpy(dtype=float)\n",
        "U_t = train_df[action_cols].to_numpy(dtype=float).reshape(len(train_df), -1)\n",
        "\n",
        "if next_state_cols is not None:\n",
        "    X_next = train_df[next_state_cols].to_numpy(dtype=float)\n",
        "else:\n",
        "    # fallback: use shift by -1 (drop last row to align)\n",
        "    X_next = np.roll(X_t, -1, axis=0)\n",
        "    X_t    = X_t[:-1, :]\n",
        "    U_t    = U_t[:-1, :]\n",
        "    X_next = X_next[:-1, :]\n",
        "\n",
        "n_samples = X_t.shape[0]\n",
        "n_state = X_t.shape[1]\n",
        "n_inputs = U_t.shape[1]\n",
        "\n",
        "assert X_next.shape == (n_samples, n_state), \"Mismatch building next-state matrix.\"\n",
        "\n",
        "# Estimate A and B via least squares:\n",
        "#    X_next ≈ X_t @ Aᵀ + U_t @ Bᵀ  =>  X_next ≈ [X_t  U_t] @ [Aᵀ; Bᵀ]\n",
        "Z = np.hstack([X_t, U_t])                      # (N, n_state + n_inputs)\n",
        "Theta, *_ = np.linalg.lstsq(Z, X_next, rcond=None)  # (n_state + n_inputs, n_state)\n",
        "\n",
        "A_new = Theta[:n_state, :].T                   # (n_state, n_state)\n",
        "B_new = Theta[n_state:, :].T                   # (n_state, n_inputs)\n",
        "\n",
        "# Keep in memory for the save cell\n",
        "A_estimated = A_new\n",
        "B_estimated = B_new\n",
        "\n",
        "# Also keep the column names for nicer headers when saving\n",
        "state_names = [c for c in state_cols]\n",
        "action_names = [c for c in action_cols]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sxidkjb5phM"
      },
      "source": [
        "Save $\\mathbf{A}$ and $\\mathbf{B}$ to \"model-A-new.tsv\" and \"model-B-new.tsv\" respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LzcREdX_5pFS"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "assert 'A_estimated' in globals() and 'B_estimated' in globals(), \"Run the Part 4 compute cell first.\"\n",
        "\n",
        "A_to_save = np.asarray(A_estimated, dtype=float)\n",
        "B_to_save = np.asarray(B_estimated, dtype=float)\n",
        "\n",
        "# Build DataFrames with helpful headers; readers in earlier parts will still work\n",
        "# A: rows=state_next (x,v,a), cols=state (x,v,a)\n",
        "A_df_new = pd.DataFrame(A_to_save, index=state_names, columns=state_names)\n",
        "# B: rows=state_next (x,v,a), cols=action(s)\n",
        "B_df_new = pd.DataFrame(B_to_save, index=state_names, columns=action_names)\n",
        "\n",
        "A_df_new.to_csv(\"model-A-new.tsv\", sep=\"\\t\", index=True)\n",
        "B_df_new.to_csv(\"model-B-new.tsv\", sep=\"\\t\", index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNkBsDgD5vIn"
      },
      "source": [
        "Submit \"model-A-new.tsv\" and \"model-B-new.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 5: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n",
        "You do not need to provide code for data collection if you did that by manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 6: Acknowledgements\n",
        "\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you did this assignment completely on your own, simply write none below.\n",
        "\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for. If you did not use any other libraries, simply write none below.\n",
        "\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy. If you did not use any generative AI tools, simply write none below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"\"\"Acknowledgments\n",
        "\n",
        "I did not discuss this assignment with anyone.\n",
        "I did not use any libraries or tools beyond those mentioned in the course modules.\n",
        "I did not use any generative AI tools to complete this assignment.\n",
        "\"\"\"\n",
        "\n",
        "with open(\"acknowledgments.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(text)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
